import asyncio
import os
import cv2
import pathlib
import sys
import time
from datetime import datetime
import pyaudio
import warnings
import traceback
import threading
import queue
from dotenv import load_dotenv  # pyright: ignore[reportMissingImports]
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from pydantic import BaseModel
import uvicorn
from typing import List
import base64
import json
import asyncio


# [Firebase ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€]
try:
    import firebase_admin
    from firebase_admin import credentials, firestore  # pyright: ignore[reportMissingImports]
except ImportError:
    print("âŒ firebase-adminì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install firebase-admin'ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    sys.exit(1)

# [Gemini ë¼ì´ë¸ŒëŸ¬ë¦¬]
try:
    from google import genai
    from google.genai import types  # pyright: ignore[reportMissingImports]
except ImportError:
    print("âŒ google-genai ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)

# [Supabase ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€]
try:
    from supabase import create_client, Client
except ImportError:
    print("âŒ supabase ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install supabase'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    sys.exit(1)

warnings.filterwarnings("ignore")

# ==========================================
# .env íŒŒì¼ ë¡œë“œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì°¾ê¸°)
# ==========================================
def load_environment():
    try:
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì°¾ê¸°
        project_root = pathlib.Path(__file__).parent.parent.absolute()
        env_path = project_root / ".env"
        
        if env_path.exists():
            load_dotenv(dotenv_path=env_path)
            print(f"âœ… .env íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {env_path}")
        else:
            print(f"âš ï¸ .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {env_path}")
    except Exception as e:
        print(f"âš ï¸ .env íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")

load_environment()

# ==========================================
API_KEY = os.getenv("GEMINI_API_KEY")

# Firebase í‚¤ ê²½ë¡œ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ìš°ì„ , ì—†ìœ¼ë©´ í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ FirebaseAdmin.json ì‚¬ìš©)
project_root = pathlib.Path(__file__).parent.parent.absolute()
current_dir = pathlib.Path(__file__).parent.absolute()

# ìš°ì„ ìˆœìœ„ 1: í™˜ê²½ë³€ìˆ˜
# ìš°ì„ ìˆœìœ„ 2: vision í´ë” ë‚´ FirebaseAdmin.json
# ìš°ì„ ìˆœìœ„ 3: í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ serviceAccountKey.json
default_key_path = "C:\dxfirebasekey\serviceAccountKey.json"
#FIREBASE_KEY_PATH = os.getenv("FIREBASE_KEY_PATH", str(default_key_path))

# Realtime Database URL (Firestore ì‚¬ìš© ì‹œ ë¶ˆí•„ìš”í•˜ì§€ë§Œ ì°¸ê³ ìš©ìœ¼ë¡œ ë‚¨ê¹€/ì‚­ì œ ê°€ëŠ¥)
FIREBASE_DATABASE_URL = "https://team-dxproject-default-rtdb.asia-southeast1.firebasedatabase.app/"

MODEL_ID = "gemini-2.5-flash-native-audio-preview-09-2025"

# [ì˜¤ë””ì˜¤ ì„¤ì •]
AUDIO_FORMAT = pyaudio.paInt16
CHANNELS = 1
INPUT_RATE = 16000
OUTPUT_RATE = 24000
CHUNK_SIZE = 512

# ==========================================
def load_environment():
    try:
        current_dir = pathlib.Path(__file__).parent.absolute()
        env_path = None
        for parent in [current_dir] + list(current_dir.parents):
            check_path = parent / ".env"
            if check_path.exists():
                env_path = check_path
                break
        if env_path:
            load_dotenv(dotenv_path=env_path)
    except Exception:
        pass

load_environment()

API_KEY = os.getenv("GEMINI_API_KEY")

# Firebase í‚¤ ê²½ë¡œ ì„¤ì • ë¡œì§ ê°œì„ 
project_root = pathlib.Path(__file__).parent.parent.absolute()
default_firebase_path = project_root / "serviceAccountKey.json"
FIREBASE_KEY_PATH = "C:\dxfirebasekey\serviceAccountKey.json"

if not API_KEY:
    print("âŒ GEMINI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

if not FIREBASE_KEY_PATH:
    print(f"âŒ Firebase í‚¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print(f"   ê²€ìƒ‰ ìœ„ì¹˜ 1: {current_dir / 'FirebaseAdmin.json'}")
    print(f"   ê²€ìƒ‰ ìœ„ì¹˜ 2: {project_root / 'Firebase.json'}")
    sys.exit(1)

MODEL_ID = "gemini-2.5-flash-native-audio-preview-09-2025"

# [ì˜¤ë””ì˜¤ ì„¤ì •]
AUDIO_FORMAT = pyaudio.paInt16
CHANNELS = 1
INPUT_RATE = 16000
OUTPUT_RATE = 24000
CHUNK_SIZE = 512




async def perform_summarization(client, session_id):
    """Firebaseì—ì„œ ëŒ€í™”ë¥¼ ê°€ì ¸ì™€ ìš”ì•½í•˜ê³  ê²°ê³¼ë¥¼ DBì— ì €ì¥"""
    print(f"\nğŸ”” [Command Received] ìš”ì•½ ìš”ì²­ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. (Session: {session_id})")
    
    try:
        db_client = firestore.client()
        # 1. ëŒ€í™” ë¡œê·¸ ê°€ì ¸ì˜¤ê¸°
        # Firestore: sessions/{session_id}/messages ì»¬ë ‰ì…˜ ì¡°íšŒ
        messages_ref = db_client.collection('sessions').document(session_id).collection('messages')
        # created_at ê¸°ì¤€ ì •ë ¬
        docs = messages_ref.order_by('created_at').stream()
        
        messages_list = []
        for doc in docs:
            messages_list.append(doc.to_dict())

        if not messages_list:
            print("   âš ï¸ ëŒ€í™” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        # 2. í…ìŠ¤íŠ¸ ë³€í™˜
        chat_context = ""
        for msg in messages_list:
            sender = msg.get('sender', 'unknown')
            content = msg.get('content', '')
            chat_context += f"[{sender}]: {content}\n"

        # 3. Geminiì—ê²Œ ìš”ì•½ ìš”ì²­ (ê°€ë²¼ìš´ ëª¨ë¸ ì‚¬ìš©)
        prompt = f"""
        ì•„ë˜ëŠ” ê°€ì „ì œí’ˆ ìˆ˜ë¦¬ AIì™€ ì‚¬ìš©ìì˜ ëŒ€í™” ë¡œê·¸ì…ë‹ˆë‹¤.
        í˜„ì¬ ì‚¬ìš©ìê°€ ê²ªê³  ìˆëŠ” 'ë¬¸ì œì 'ê³¼ 'ì¦ìƒ'ì„ 
        ê¸°ìˆ ì ì¸ ê´€ì ì—ì„œ ëª…í™•í•˜ê²Œ 1ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
        
        [ëŒ€í™” ë¡œê·¸]
        {chat_context}
        """

        # Gemini í˜¸ì¶œ
        resp = await client.aio.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt
        )
        summary_text = resp.text.strip()
        print(f"   ğŸ“ ìš”ì•½ ì™„ë£Œ: {summary_text}")

        # 4. ê²°ê³¼ DB ì €ì¥ ë° ëª…ë ¹ì–´ ì´ˆê¸°í™”
        # summary í•„ë“œì— ê²°ê³¼ ì €ì¥
        db_client.collection('sessions').document(session_id).update({
            'summary': summary_text,
            'command': None  # ëª…ë ¹ ìˆ˜í–‰ ì™„ë£Œ í›„ ì´ˆê¸°í™” (ì¤‘ìš”)
        })

    except Exception as e:
        print(f"   âŒ ìš”ì•½ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")



# ==========================================
# [í´ë˜ìŠ¤] Firebase Logger (Firestore ì‚¬ìš©)
# ==========================================
class FirebaseLogger:
    def __init__(self):
        self.session_ref = None
        self.current_turn_text = ""
        self.last_user_text = ""  # ì¤‘ë³µ ì €ì¥ ë°©ì§€ìš©
        self.db = None
        self._init_firebase()
        self._start_session()

    def _init_firebase(self):
        # ì´ë¯¸ ì•±ì´ ì´ˆê¸°í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ì¤‘ë³µ ì´ˆê¸°í™” ë°©ì§€)
        if not firebase_admin._apps:
            try:
                if not os.path.exists(FIREBASE_KEY_PATH):
                    print(f"âŒ í‚¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FIREBASE_KEY_PATH}")
                    sys.exit(1)
                    
                cred = credentials.Certificate(FIREBASE_KEY_PATH)
                firebase_admin.initialize_app(cred)
                print(f"ğŸ”¥ Firebase ì—°ê²° ì„±ê³µ!")
            except Exception as e:
                print(f"âŒ Firebase ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
                sys.exit(1)
        
        self.db = firestore.client()

    def _start_session(self):
        try:
            # 'sessions' ì»¬ë ‰ì…˜ì— ìƒˆ ì„¸ì…˜ ìƒì„± (add)
            update_time, self.session_ref = self.db.collection('sessions').add({
                'start_time': int(time.time() * 1000),  # timestamp (ms)
                'model_id': MODEL_ID,
                'status': 'active'
            })
            print(f"ğŸ“„ ìƒˆ ì„¸ì…˜ ID: {self.session_ref.id}")
        except Exception as e:
            print(f"âŒ ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")

    def log_message(self, sender, text):
        if not self.session_ref:
            print(f"âš ï¸ [Firebase] session_refê°€ Noneì…ë‹ˆë‹¤. ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        if not text or not text.strip():
            print(f"âš ï¸ [Firebase] ë¹ˆ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return
        try:
            # í˜„ì¬ ì‹œê°„ ì •ë³´ ìƒì„±
            current_timestamp = int(time.time() * 1000)  # ë°€ë¦¬ì´ˆ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„
            current_datetime = datetime.now()  # í˜„ì¬ ë‚ ì§œ/ì‹œê°„ ê°ì²´
            
            # ì½ê¸° ì‰¬ìš´ ë‚ ì§œ/ì‹œê°„ í˜•ì‹ (í•œêµ­ ì‹œê°„ëŒ€ ê¸°ì¤€)
            # ì˜ˆ: "2024-01-15 14:30:25"
            formatted_time = current_datetime.strftime("%Y-%m-%d %H:%M:%S")
            
            # ì‹œê°„ëŒ€ ì •ë³´ (í•œêµ­ í‘œì¤€ì‹œ)
            timezone = "KST"
            
            print(f"ğŸ’¾ [Firebase] ì €ì¥ ì‹œë„ - sender: {sender}, text: {text[:50]}..., ì‹œê°„: {formatted_time}")
            # í•´ë‹¹ ì„¸ì…˜ì˜ 'messages' ì»¬ë ‰ì…˜ì— ëŒ€í™” ì¶”ê°€
            doc_ref = self.session_ref.collection('messages').add({
                'sender': sender,      # 'user' or 'gemini'
                'content': text,       # ë©”ì‹œì§€ ë‚´ìš© (ì£¼ í•„ë“œ)
                'text': text,          # RAG/mod_chatbot_server.pyì™€ í†µì¼ì„ ìœ„í•´ text í•„ë“œë„ ì¶”ê°€
                'message_type': 'live',  # ë©”ì‹œì§€ íƒ€ì…: 'live' (ì‹¤ì‹œê°„ ëŒ€í™”)
                'created_at': current_timestamp,  # ë°€ë¦¬ì´ˆ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„ (ì •ë ¬/ì¿¼ë¦¬ìš©)
                'timestamp': formatted_time,      # ì½ê¸° ì‰¬ìš´ ë‚ ì§œ/ì‹œê°„ í˜•ì‹
                'timezone': timezone              # ì‹œê°„ëŒ€ ì •ë³´
            })
            print(f"âœ… [Firebase] ì €ì¥ ì„±ê³µ! - sender: {sender}, text ê¸¸ì´: {len(text)}, ì‹œê°„: {formatted_time}")
        except Exception as e:
            print(f"âŒ [Firebase] ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()

    def append_text(self, text):
        """ìŠ¤íŠ¸ë¦¬ë°ë˜ëŠ” í…ìŠ¤íŠ¸ ì¡°ê°ì„ ì„ì‹œ ë²„í¼ì— ì¶”ê°€"""
        if text:
            print(f"ğŸ“ [ë²„í¼] í…ìŠ¤íŠ¸ ì¶”ê°€: '{text[:50]}...' (í˜„ì¬ ë²„í¼ ê¸¸ì´: {len(self.current_turn_text)})")
            self.current_turn_text += text
        else:
            print(f"âš ï¸ [ë²„í¼] ë¹ˆ í…ìŠ¤íŠ¸ê°€ append_textì— ì „ë‹¬ë¨")

    def flush_model_turn(self):
        """ë²„í¼ì— ëª¨ì¸ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ë¡œê·¸ë¡œ ì €ì¥í•˜ê³  ì´ˆê¸°í™”"""
        if self.current_turn_text.strip():
            print(f"ğŸ’¾ [Firebase] AI ì‘ë‹µ ì €ì¥ ì‹œë„ - ê¸¸ì´: {len(self.current_turn_text)}")
            self.log_message('gemini', self.current_turn_text)
            self.current_turn_text = ""
        else:
            print(f"âš ï¸ [Firebase] AI ì‘ë‹µ ë²„í¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")


# ==========================================
# [í´ë˜ìŠ¤] Supabase RAG Engine
# ==========================================

# ==========================================
# [í´ë˜ìŠ¤] Supabase Hybrid RAG Engine (í…ìŠ¤íŠ¸ + ë²¡í„°)
# ==========================================

# ==========================================
# [ìˆ˜ì •ë¨] Supabase Hybrid RAG Engine
# ==========================================
class SupabaseRAG:
    def __init__(self, gemini_client):
        self.gemini_client = gemini_client
        # ë‹¤ë¥¸ íŒŒì¼ë“¤ê³¼ ë™ì¼í•œ Supabase URL ì‚¬ìš© (ê¸°ë³¸ê°’)
        # .env íŒŒì¼ì—ì„œ SUPABASE_URLì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        self.supabase_url = os.getenv("SUPABASE_URL", "https://wzafalbctqkylhyzlfej.supabase.co")
        # .env íŒŒì¼ì—ì„œ supbase_service_role í‚¤ ê°€ì ¸ì˜¤ê¸°
        self.supabase_key = os.getenv("supbase_service_role") 
        self.client = None
        
        if self.supabase_key:
            try:
                self.client = create_client(self.supabase_url, self.supabase_key)
                print(f"ğŸ”¥ Supabase í•˜ì´ë¸Œë¦¬ë“œ ì—”ì§„ ì—°ê²° ì„±ê³µ!")
                print(f"   URL: {self.supabase_url}")
            except Exception as e:
                print(f"âŒ Supabase ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
                print(f"   âš ï¸ Supabase ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
        else:
            print("âš ï¸ Supabase Key(supbase_service_role)ë¥¼ .env íŒŒì¼ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   âš ï¸ Supabase RAG ê¸°ëŠ¥ì€ ë¹„í™œì„±í™”ë˜ì§€ë§Œ, ë‹¤ë¥¸ ê¸°ëŠ¥ì€ ê³„ì† ì‘ë™í•©ë‹ˆë‹¤.")
            print(f"   .env íŒŒì¼ ìœ„ì¹˜: {pathlib.Path(__file__).parent.parent.absolute() / '.env'}")

    def get_embedding(self, text):
        if not self.gemini_client: return None
        try:
            # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (Gemini)
            response = self.gemini_client.models.embed_content(
                model="text-embedding-004",
                contents=text,
                config=types.EmbedContentConfig(
                    task_type="RETRIEVAL_QUERY"
                )
            )
            if hasattr(response, 'embeddings') and response.embeddings:
                return response.embeddings[0].values
            return None
        except Exception as e:
            print(f"âš ï¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ (í…ìŠ¤íŠ¸ ê²€ìƒ‰ë§Œ ì‹œë„): {e}")
            return None

    def search(self, query, k=3):
        if not self.client: return []
        
        # 1. ë²¡í„° ìƒì„±
        embedding = self.get_embedding(query)
        
        # ì„ë² ë”© ì‹¤íŒ¨ ì‹œ 0ìœ¼ë¡œ ì±„ìš´ ë”ë¯¸ ë²¡í„° ì‚¬ìš©
        if not embedding: 
            embedding = [0.0] * 768 

        # 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìš”ì²­
        # (SQL í•¨ìˆ˜ íŒŒë¼ë¯¸í„° ì´ë¦„ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤)
        params = {
            "query_text": query,          
            "query_embedding": embedding, 
            "match_threshold": 0.45,      
            "match_count": k              
        }
        
        try:
            # RPC í˜¸ì¶œ: hybrid_search
            response = self.client.rpc("hybrid_search", params).execute()
            
            results = []
            seen_content = set()
            
            data = response.data if response.data else []
            
            for row in data:
                content = row.get('content_text', '')
                if content and content not in seen_content:
                    results.append(content)
                    seen_content.add(content)
            
            return results
        except Exception as e:
            print(f"âŒ Supabase ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

# ==========================================
# [í´ë˜ìŠ¤] ë¹„ë™ê¸° ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´
# ==========================================
class AsyncAudioPlayer:
    def __init__(self):
        self.queue = queue.Queue()
        self.p = pyaudio.PyAudio()
        self.stream = self.p.open(
            format=AUDIO_FORMAT,
            channels=CHANNELS,
            rate=OUTPUT_RATE,
            output=True
        )
        self.running = True
        self.is_playing = False
        self.thread = threading.Thread(target=self._play_loop, daemon=True)
        self.thread.start()

    def _play_loop(self):
        while self.running:
            try:
                data = self.queue.get(timeout=0.05)
                self.is_playing = True
                self.stream.write(data)
            except queue.Empty:
                self.is_playing = False
                continue
            except Exception:
                pass

    def add_audio(self, data):
        self.queue.put(data)

    def close(self):
        self.running = False
        if self.thread.is_alive():
            self.thread.join()
        self.stream.stop_stream()
        self.stream.close()
        self.p.terminate()

# ==========================================
# [ì„¤ì •] Config
# ==========================================
def get_config():
    current_dir = pathlib.Path(__file__).parent.absolute()
    persona_path = current_dir / "persona/persona_ì„¸íƒê¸°ì‚¬ìš©ë²•.txt"
    
    system_instruction = "ë„ˆëŠ” ë„ì›€ì´ ë˜ëŠ” LGì „ìì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì•¼."
    if persona_path.exists():
        try:
            system_instruction = persona_path.read_text(encoding="utf-8")
        except Exception:
            pass

    return {
        "response_modalities": ["AUDIO"],  # ì˜¤ë””ì˜¤ë§Œ ë°›ê¸° (í…ìŠ¤íŠ¸ëŠ” output_audio_transcriptionì—ì„œ ì¶”ì¶œ)
        "input_audio_transcription": {},  # ì…ë ¥ ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        "output_audio_transcription": {},  # ì¶œë ¥ ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (AI ì‘ë‹µ)
        "speech_config": {
            "voice_config": {
                "prebuilt_voice_config": {
                    "voice_name": "Laomedeia" # ëª©ì†Œë¦¬ ë°”ê¾¸ê¸°
                }
            }
        },
        "system_instruction": system_instruction
    }


# ==========================================
# [API ì„¤ì •] FastAPI & Chat Endpoint
# ==========================================
app = FastAPI()
chat_client = None
chat_rag_engine = None

class ChatRequest(BaseModel):
    user_id: str
    user_message: str

class ChatResponse(BaseModel):
    answer: str

@app.on_event("startup")
async def startup_event():
    global chat_client, chat_rag_engine
    # APIìš© í´ë¼ì´ì–¸íŠ¸ ë³„ë„ ì´ˆê¸°í™”
    chat_client = genai.Client(api_key=API_KEY)
    chat_rag_engine = SupabaseRAG(chat_client)

@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(req: ChatRequest):
    print(f"ğŸ“© [Spring -> Python] ìš”ì²­ ë„ì°©: {req.user_message}")
    
    context_text = ""
    if chat_rag_engine:
        # RAG ê²€ìƒ‰ ì‹¤í–‰
        results = chat_rag_engine.search(req.user_message, k=3)
        if results:
            context_text = "\n\n".join(results)
            print(f"   âœ… ê²€ìƒ‰ ì„±ê³µ: {len(results)}ê±´")
        else:
            print("   âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
    
    prompt = f"""
    ë‹¹ì‹ ì€ LGì „ì ê°€ì „ì œí’ˆ ìˆ˜ë¦¬ ë° ì‚¬ìš©ë²•ì„ ì•ˆë‚´í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ì•„ë˜ [ë§¤ë‰´ì–¼ ì •ë³´]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.
    ë§¤ë‰´ì–¼ì— ê´€ë ¨ ì •ë³´ê°€ ì—†ë‹¤ë©´, ì¼ë°˜ì ì¸ ì§€ì‹ì„ í™œìš©í•˜ë˜ "ë§¤ë‰´ì–¼ì—ëŠ” ì—†ëŠ” ë‚´ìš©ì´ì§€ë§Œ..."ì´ë¼ê³  ì–¸ê¸‰í•´ ì£¼ì„¸ìš”.

    [ë§¤ë‰´ì–¼ ì •ë³´]
    {context_text}

    [ì‚¬ìš©ì ì§ˆë¬¸]
    {req.user_message}
    """

    try:
        response = chat_client.models.generate_content(
            model="gemini-1.5-flash",
            contents=prompt
        )
        return ChatResponse(answer=response.text)
    except Exception as e:
        print(f"âŒ ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
        return ChatResponse(answer="ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

@app.websocket("/ws/chat")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    print("ğŸ“± Flutter Client Connected")
    
    # Gemini Live ì„¸ì…˜ ì¤€ë¹„
    config = get_config()
    client = genai.Client(api_key=API_KEY)
    
    # í ìƒì„±
    video_queue = asyncio.Queue()
    audio_queue = asyncio.Queue()
    
    async with client.aio.live.connect(model=MODEL_ID, config=config) as session:
        print("âœ… Gemini Live Session Started")

        # [Task 1] WebSocket -> Gemini (Receive from Flutter)
        async def receive_from_flutter():
            try:
                while True:
                    # í…ìŠ¤íŠ¸(JSON)ë¡œ ìˆ˜ì‹  (ì´ë¯¸ì§€/ì˜¤ë””ì˜¤ëŠ” Base64 ì¸ì½”ë”©ë¨)
                    data = await websocket.receive_text()
                    message = json.loads(data)
                    
                    if message['type'] == 'audio':
                        # Base64 -> Bytes -> Gemini
                        audio_bytes = base64.b64decode(message['data'])
                        await session.send_realtime_input(
                            audio=types.Blob(data=audio_bytes, mime_type="audio/pcm;rate=16000")
                        )
                    elif message['type'] == 'image':
                        # Base64 -> Bytes -> Gemini
                        image_bytes = base64.b64decode(message['data'])
                        await session.send_realtime_input(
                            video=types.Blob(data=image_bytes, mime_type="image/jpeg")
                        )
                    elif message['type'] == 'text':
                        # í…ìŠ¤íŠ¸ ë©”ì‹œì§€ (RAG ê²€ìƒ‰ ë“±ì— í™œìš© ê°€ëŠ¥)
                        pass
                        
            except WebSocketDisconnect:
                print("ğŸ”Œ Client Disconnected")
            except Exception as e:
                print(f"Receive Error: {e}")

        # [Task 2] Gemini -> WebSocket (Send to Flutter)
        async def send_to_flutter():
            try:
                while True:
                    async for response in session.receive():
                        if response.server_content:
                            model_turn = response.server_content.model_turn
                            if model_turn:
                                for part in model_turn.parts:
                                    # ì˜¤ë””ì˜¤ ë°ì´í„°
                                    if part.inline_data:
                                        audio_b64 = base64.b64encode(part.inline_data.data).decode('utf-8')
                                        await websocket.send_json({
                                            "type": "audio",
                                            "data": audio_b64
                                        })
                                    
                                    # í…ìŠ¤íŠ¸ ë°ì´í„°
                                    if part.text:
                                        await websocket.send_json({
                                            "type": "text",
                                            "data": part.text
                                        })
                                        
                                    # í„´ ì¢…ë£Œ ì‹œê·¸ë„ (í•„ìš”í•˜ë©´ ì „ì†¡)
                                    # if getattr(response.server_content, "turn_complete", False): ...

            except Exception as e:
                print(f"Send Error: {e}")

        # íƒœìŠ¤í¬ ì‹¤í–‰
        await asyncio.gather(receive_from_flutter(), send_to_flutter())


# ==========================================
# [ë©”ì¸] ì‹¤í–‰ ë£¨í”„
# ==========================================
async def main():
    try:
        client = genai.Client(api_key=API_KEY)
        config = get_config()
        
        p = pyaudio.PyAudio()
        input_stream = p.open(format=AUDIO_FORMAT, channels=CHANNELS, rate=INPUT_RATE, input=True, frames_per_buffer=CHUNK_SIZE)
        audio_player = AsyncAudioPlayer()

        # USB ì›¹ìº  ì´ˆê¸°í™” (Windows DirectShow ë°±ì—”ë“œ ì‚¬ìš©)
        cap = None
        camera_index = 0
        max_cameras = 5  # ìµœëŒ€ 5ê°œê¹Œì§€ ì‹œë„
        
        print("ğŸ“¹ USB ì›¹ìº  ì—°ê²° ì‹œë„ ì¤‘...")
        for i in range(max_cameras):
            # Windowsì—ì„œ DirectShow ë°±ì—”ë“œ ì‚¬ìš© (USB ì›¹ìº ì— ë” ì•ˆì •ì )
            try:
                # DirectShow ë°±ì—”ë“œ ì‚¬ìš© (Windows ì „ìš©)
                test_cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)
            except:
                # CAP_DSHOWê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë°±ì—”ë“œ ì‚¬ìš©
                test_cap = cv2.VideoCapture(i)
            
            if test_cap.isOpened():
                # í”„ë ˆì„ ì½ê¸° í…ŒìŠ¤íŠ¸
                ret, frame = test_cap.read()
                if ret and frame is not None:
                    # USB ì›¹ìº ì¸ì§€ í™•ì¸ (ì¼ë°˜ì ìœ¼ë¡œ ì™¸ë¶€ ì›¹ìº ì€ ì¸ë±ìŠ¤ 1 ì´ìƒ)
                    # ë˜ëŠ” ì²« ë²ˆì§¸ë¡œ ì„±ê³µí•œ ì›¹ìº  ì‚¬ìš©
                    cap = test_cap
                    camera_index = i
                    print(f"âœ… USB ì›¹ìº  ì—°ê²° ì„±ê³µ! (ì¸ë±ìŠ¤: {i})")
                    # ì›¹ìº  ì´ë¦„ ì •ë³´ ì¶œë ¥ (ê°€ëŠ¥í•œ ê²½ìš°)
                    try:
                        backend = test_cap.getBackendName()
                        print(f"   ë°±ì—”ë“œ: {backend}")
                    except:
                        pass
                    break
                else:
                    test_cap.release()
            else:
                test_cap.release()
        
        if cap is None or not cap.isOpened():
            print("âŒ USB ì›¹ìº ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   ê°€ëŠ¥í•œ í•´ê²° ë°©ë²•:")
            print("   1. USB ì›¹ìº ì´ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
            print("   2. ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì—ì„œ ì›¹ìº ì„ ì‚¬ìš© ì¤‘ì¸ì§€ í™•ì¸ (Zoom, Teams, ì¹´ë©”ë¼ ì•± ë“±)")
            print("   3. ì›¹ìº  ê¶Œí•œì„ í™•ì¸ (Windows ì„¤ì • > ê°œì¸ ì •ë³´ > ì¹´ë©”ë¼)")
            print("   4. USB í¬íŠ¸ë¥¼ ë‹¤ë¥¸ í¬íŠ¸ë¡œ ë³€ê²½í•´ë³´ì„¸ìš”")
            print("   5. ì›¹ìº  ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ì¥ì¹˜ ê´€ë¦¬ì)")
            sys.exit(1)
        
        # ì›¹ìº  ì„¤ì •
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 480)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 640)
        
        # ì‹¤ì œ ì„¤ì •ëœ í•´ìƒë„ í™•ì¸
        actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        print(f"ğŸ“ ì›¹ìº  í•´ìƒë„: {actual_width}x{actual_height}")
        
        # ì›¹ìº ì´ ì‹¤ì œë¡œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ìˆëŠ”ì§€ í…ŒìŠ¤íŠ¸
        print("ğŸ” ì›¹ìº  í”„ë ˆì„ ì½ê¸° í…ŒìŠ¤íŠ¸ ì¤‘...")
        time.sleep(0.5)  # ì›¹ìº  ì´ˆê¸°í™” ëŒ€ê¸°
        test_ret, test_frame = cap.read()
        if not test_ret or test_frame is None:
            print("âŒ ì›¹ìº ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   ê°€ëŠ¥í•œ í•´ê²° ë°©ë²•:")
            print("   1. ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì—ì„œ ì›¹ìº ì„ ì‚¬ìš© ì¤‘ì¸ì§€ í™•ì¸ (Zoom, Teams, ì¹´ë©”ë¼ ì•± ë“±)")
            print("   2. ì›¹ìº ì„ ë‹¤ì‹œ ì—°ê²°í•´ë³´ì„¸ìš”")
            print("   3. Windows ì„¤ì • > ê°œì¸ ì •ë³´ > ì¹´ë©”ë¼ ê¶Œí•œ í™•ì¸")
            cap.release()
            sys.exit(1)
        else:
            print(f"âœ… ì›¹ìº  í”„ë ˆì„ ì½ê¸° ì„±ê³µ! (í”„ë ˆì„ í¬ê¸°: {test_frame.shape})")

        shared_state = {
            "latest_frame": None, 
            "running": True
        }

        # [ì¤‘ìš”] Firebase ë¡œê±° ì´ˆê¸°í™”
        logger = FirebaseLogger()
        
        # [ì¤‘ìš”] Supabase RAG ì´ˆê¸°í™”
        rag_engine = SupabaseRAG(client)
        rag_queue = asyncio.Queue()

        def on_model_speak(text):
            print(f"[ğŸ¤– Gemini]: {text}")
            logger.log_message('gemini', text)

        print(f"\nğŸš€ ëª¨ë¸({MODEL_ID}) ì—°ê²° ì¤‘...")

        async with client.aio.live.connect(model=MODEL_ID, config=config) as session:
            print("âœ… ì—°ê²° ì„±ê³µ! (ì¢…ë£Œ: q)")
            
            # [Task 1] í™”ë©´ í‘œì‹œ (Clean View)
            async def display_loop():
                frame_error_count = 0
                max_errors = 10
                
                while shared_state["running"]:
                    ret, frame = cap.read()
                    
                    if not ret or frame is None:
                        frame_error_count += 1
                        if frame_error_count > max_errors:
                            print("âŒ ì›¹ìº  í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨ê°€ ê³„ì†ë©ë‹ˆë‹¤. ì›¹ìº ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                            shared_state["running"] = False
                            break
                        await asyncio.sleep(0.1)
                        continue
                    
                    # í”„ë ˆì„ ì½ê¸° ì„±ê³µ ì‹œ ì—ëŸ¬ ì¹´ìš´í„° ë¦¬ì…‹
                    frame_error_count = 0
                    
                    shared_state["latest_frame"] = frame.copy()
                    cv2.imshow('Gemini Live Vision', frame)
                    
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        shared_state["running"] = False
                        break
                    await asyncio.sleep(0.01)

            # [Task 2] ë¹„ë””ì˜¤ ì „ì†¡
            async def send_video():
                while shared_state["running"]:
                    if shared_state["latest_frame"] is not None:
                        frame = cv2.resize(shared_state["latest_frame"], (640, 480))
                        _, buffer = cv2.imencode('.jpg', frame, [int(cv2.IMWRITE_JPEG_QUALITY), 50])
                        try:
                            await session.send_realtime_input(
                                video=types.Blob(data=buffer.tobytes(), mime_type="image/jpeg")
                            )
                        except Exception: pass
                    await asyncio.sleep(0.5)

            # [Task 3] ì˜¤ë””ì˜¤ ì…ë ¥ (User)
            async def send_audio():
                while shared_state["running"]:
                    try:
                        data = await asyncio.to_thread(input_stream.read, CHUNK_SIZE, exception_on_overflow=False)
                        
                        # [ìˆ˜ì •] ë´‡ì´ ë§í•˜ê³  ìˆì„ ë•ŒëŠ” ë§ˆì´í¬ ì…ë ¥ì„ ëª¨ë¸ì— ë³´ë‚´ì§€ ì•ŠìŒ (Self-Interruption ë°©ì§€)
                        if audio_player.is_playing:
                            continue

                        await session.send_realtime_input(audio=types.Blob(data=data, mime_type="audio/pcm;rate=16000"))
                    except Exception: break

# [Task 4] ì‘ë‹µ ìˆ˜ì‹  (ìƒê° í”„ë¡œì„¸ìŠ¤ ìˆ¨ê¸°ê¸° ì ìš©)
            async def receive_response():
                print("   ğŸ‘‚ ì‘ë‹µ ëŒ€ê¸° ì¤‘...")
                response_count = 0
                while shared_state["running"]:
                    try:
                        async for response in session.receive():
                            response_count += 1
                            
                            # [ì¶”ê°€] ìŒì„± ì¸ì‹ ì´ë²¤íŠ¸ ì²˜ë¦¬ - ì‚¬ìš©ì ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ì €ì¥
                            # Gemini Live APIì˜ response êµ¬ì¡° í™•ì¸
                            speech_recognition = None
                            
                            # ë°©ë²• 1: responseì˜ ì§ì ‘ ì†ì„±
                            if hasattr(response, 'speech_recognition_event'):
                                speech_recognition = response.speech_recognition_event
                            
                            # ë°©ë²• 2: server_content ì•ˆì— ìˆì„ ìˆ˜ë„ ìˆìŒ
                            if speech_recognition is None:
                                server_content_temp = getattr(response, 'server_content', None)
                                if server_content_temp:
                                    if hasattr(server_content_temp, 'speech_recognition_event'):
                                        speech_recognition = server_content_temp.speech_recognition_event
                            
                            # ë°©ë²• 3: response ê°ì²´ ì „ì²´ êµ¬ì¡° í™•ì¸ (ì²˜ìŒ ëª‡ ë²ˆë§Œ)
                            if response_count <= 3:
                                print(f"ğŸ” [ë””ë²„ê·¸ #{response_count}] response íƒ€ì…: {type(response)}")
                                response_attrs = [attr for attr in dir(response) if not attr.startswith('_')]
                                print(f"ğŸ” [ë””ë²„ê·¸] response ì†ì„±: {response_attrs[:10]}...")  # ì²˜ìŒ 10ê°œë§Œ
                            
                            if speech_recognition:
                                print(f"ğŸ” [ë””ë²„ê·¸] speech_recognition ì´ë²¤íŠ¸ ë°œê²¬! íƒ€ì…: {type(speech_recognition)}")
                                # transcript ì†ì„± í™•ì¸ (ë‹¤ì–‘í•œ ê°€ëŠ¥í•œ ì†ì„± ì´ë¦„ ì‹œë„)
                                recognized_text = None
                                
                                # ê°€ëŠ¥í•œ ì†ì„± ì´ë¦„ë“¤ ì‹œë„
                                for attr_name in ['transcript', 'text', 'content', 'message']:
                                    if hasattr(speech_recognition, attr_name):
                                        attr_value = getattr(speech_recognition, attr_name)
                                        if attr_value:
                                            recognized_text = str(attr_value)
                                            print(f"ğŸ” [ë””ë²„ê·¸] '{attr_name}' ì†ì„±ì—ì„œ í…ìŠ¤íŠ¸ ë°œê²¬: {recognized_text[:50]}")
                                            break
                                
                                # ì†ì„±ì„ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ ëª¨ë“  ì†ì„± ì¶œë ¥
                                if recognized_text is None:
                                    speech_attrs = [attr for attr in dir(speech_recognition) if not attr.startswith('_')]
                                    print(f"ğŸ” [ë””ë²„ê·¸] speech_recognition ì†ì„±: {speech_attrs}")
                                    # ê°’ì´ ìˆëŠ” ì†ì„±ë§Œ ì¶œë ¥
                                    for attr in speech_attrs:
                                        try:
                                            value = getattr(speech_recognition, attr)
                                            if value and not callable(value):
                                                print(f"   - {attr}: {value}")
                                        except:
                                            pass
                                
                                if recognized_text and recognized_text.strip():
                                    # is_finalì´ Trueì¼ ë•Œë§Œ ìµœì¢… ì¸ì‹ëœ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥
                                    is_final = getattr(speech_recognition, 'is_final', False)
                                    print(f"ğŸ” [ë””ë²„ê·¸] ì¸ì‹ëœ í…ìŠ¤íŠ¸: '{recognized_text}', is_final: {is_final}")
                                    if is_final:
                                        print(f"\nğŸ¤ [ì‚¬ìš©ì ìŒì„± ì¸ì‹] {recognized_text}")
                                        logger.log_message('user', recognized_text.strip())
                                    else:
                                        # ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ëŠ” í™”ë©´ì—ë§Œ í‘œì‹œ (ì €ì¥í•˜ì§€ ì•ŠìŒ)
                                        print(f"\rğŸ¤ [ì¸ì‹ ì¤‘...] {recognized_text}", end="", flush=True)

                            server_content = response.server_content
                            if server_content is None:
                                continue

                            # server_contentì˜ ëª¨ë“  ì†ì„± í™•ì¸ (ì²˜ìŒ ëª‡ ë²ˆë§Œ)
                            if response_count <= 3:
                                server_attrs = [attr for attr in dir(server_content) if not attr.startswith('_')]
                                print(f"ğŸ” [ë””ë²„ê·¸ #{response_count}] server_content ì†ì„±: {server_attrs}")
                                # ì£¼ìš” ì†ì„±ë“¤ì˜ ê°’ í™•ì¸
                                for attr in ['transcript', 'model_turn', 'turn_complete', 'speech_recognition_event', 'input_transcription', 'output_transcription']:
                                    if hasattr(server_content, attr):
                                        value = getattr(server_content, attr)
                                        print(f"   - {attr}: {type(value)} = {str(value)[:100] if value else 'None'}")

                            # [í•µì‹¬] output_audio_transcriptionì—ì„œ AI ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                            output_transcription = getattr(server_content, 'output_transcription', None)
                            if output_transcription:
                                transcript_text = getattr(output_transcription, 'text', None)
                                if transcript_text:
                                    print(f"ğŸ” [ë””ë²„ê·¸] output_transcription.text ë°œê²¬: '{transcript_text[:50]}...'")
                                    print(transcript_text, end="", flush=True)
                                    logger.append_text(transcript_text)

                            # [í•µì‹¬] input_audio_transcriptionì—ì„œ ì‚¬ìš©ì ìŒì„± í…ìŠ¤íŠ¸ ì¶”ì¶œ
                            input_transcription = getattr(server_content, 'input_transcription', None)
                            if input_transcription:
                                input_text = getattr(input_transcription, 'text', None)
                                # is_final ì†ì„± í™•ì¸ (ìµœì¢… ê²°ê³¼ë§Œ ì €ì¥)
                                is_final = getattr(input_transcription, 'is_final', True)  # ê¸°ë³¸ê°’ì€ True
                                
                                if input_text and input_text.strip() and is_final:
                                    # ì¤‘ë³µ ì €ì¥ ë°©ì§€ (ê°™ì€ í…ìŠ¤íŠ¸ê°€ ì—°ì†ìœ¼ë¡œ ì˜¤ëŠ” ê²½ìš°)
                                    if input_text.strip() != logger.last_user_text:
                                        print(f"ğŸ” [ë””ë²„ê·¸] input_transcription.text ë°œê²¬: '{input_text[:50]}...'")
                                        print(f"\nğŸ¤ [ì‚¬ìš©ì ìŒì„± ì¸ì‹] {input_text}")
                                        logger.log_message('user', input_text.strip())
                                        logger.last_user_text = input_text.strip()
                                    else:
                                        print(f"ğŸ” [ë””ë²„ê·¸] input_transcription.text ì¤‘ë³µ (ì €ì¥ ìƒëµ): '{input_text[:50]}...'")
                                elif input_text and input_text.strip() and not is_final:
                                    # ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ëŠ” í™”ë©´ì—ë§Œ í‘œì‹œ
                                    print(f"\rğŸ¤ [ì¸ì‹ ì¤‘...] {input_text}", end="", flush=True)

                            model_turn = server_content.model_turn
                            if model_turn:
                                parts = getattr(model_turn, 'parts', [])
                                print(f"ğŸ” [ë””ë²„ê·¸ #{response_count}] model_turn ë°œê²¬! parts ê°œìˆ˜: {len(parts)}")
                                
                                for idx, part in enumerate(parts):
                                    # [í•µì‹¬ ìˆ˜ì •] "ìƒê°(Thought)" ë°ì´í„°ë©´ ì¶œë ¥í•˜ì§€ ì•Šê³  ê±´ë„ˆëœ€
                                    # google-genai ìµœì‹  ë²„ì „ì—ì„œëŠ” part.thought ì†ì„±ìœ¼ë¡œ êµ¬ë¶„ ê°€ëŠ¥
                                    is_thought = getattr(part, "thought", False)
                                    if is_thought:
                                        print(f"ğŸ” [ë””ë²„ê·¸] part[{idx}]ëŠ” ìƒê°(thought)ì´ë¯€ë¡œ ê±´ë„ˆëœ€")
                                        continue

                                    # 1. í…ìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬ (ìš°ì„  ì²˜ë¦¬ - í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì €ì¥)
                                    part_text = getattr(part, 'text', None)
                                    if part_text:
                                        print(f"ğŸ” [ë””ë²„ê·¸] part[{idx}] í…ìŠ¤íŠ¸ ë°œê²¬: '{part_text[:50]}...'")
                                        print(part_text, end="", flush=True)
                                        logger.append_text(part_text)

                                    # 2. ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬
                                    inline_data = getattr(part, 'inline_data', None)
                                    if inline_data:
                                        print(f"ğŸ” [ë””ë²„ê·¸] part[{idx}] ì˜¤ë””ì˜¤ ë°ì´í„° ë°œê²¬ (í¬ê¸°: {len(inline_data.data)} bytes)")
                                        audio_player.add_audio(inline_data.data)
                                    
                                    # í…ìŠ¤íŠ¸ë„ ì˜¤ë””ì˜¤ë„ ì—†ëŠ” ê²½ìš° - ëª¨ë“  ì†ì„± í™•ì¸
                                    if not part_text and not inline_data:
                                        print(f"ğŸ” [ë””ë²„ê·¸ #{response_count}] part[{idx}]ì—ëŠ” í…ìŠ¤íŠ¸ì™€ ì˜¤ë””ì˜¤ê°€ ëª¨ë‘ ì—†ìŒ")
                                        # partì˜ ëª¨ë“  ì†ì„± í™•ì¸
                                        part_attrs = [attr for attr in dir(part) if not attr.startswith('_')]
                                        print(f"   part ì†ì„±: {part_attrs}")
                                        # ê° ì†ì„±ì˜ ê°’ í™•ì¸
                                        for attr in part_attrs[:15]:  # ì²˜ìŒ 15ê°œë§Œ
                                            try:
                                                value = getattr(part, attr)
                                                if not callable(value):
                                                    print(f"   - {attr}: {type(value)} = {str(value)[:80] if value else 'None'}")
                                            except:
                                                pass
                            else:
                                # model_turnì´ ì—†ëŠ” ê²½ìš°ë„ ë¡œê·¸
                                if response_count <= 5:
                                    print(f"ğŸ” [ë””ë²„ê·¸ #{response_count}] model_turnì´ ì—†ìŠµë‹ˆë‹¤. server_content ì†ì„± ì¬í™•ì¸:")
                                    server_attrs = [attr for attr in dir(server_content) if not attr.startswith('_')]
                                    for attr in server_attrs:
                                        try:
                                            value = getattr(server_content, attr)
                                            if not callable(value) and value is not None:
                                                print(f"   - {attr}: {type(value)} = {str(value)[:80]}")
                                        except:
                                            pass

                            # 3. í„´ ì¢…ë£Œ ì‹ í˜¸ ì²˜ë¦¬
                            if server_content.turn_complete:
                                print(f"\nğŸ” [ë””ë²„ê·¸] turn_complete ì‹ í˜¸ ìˆ˜ì‹ ! (response_count: {response_count}, ë²„í¼ ê¸¸ì´: {len(logger.current_turn_text)})")
                                # turn_complete ì „ê¹Œì§€ ë°›ì€ ëª¨ë“  ì‘ë‹µ ìš”ì•½
                                if len(logger.current_turn_text) == 0:
                                    print(f"âš ï¸ [ê²½ê³ ] turn_completeê¹Œì§€ ì´ {response_count}ê°œì˜ ì‘ë‹µì„ ë°›ì•˜ì§€ë§Œ ë²„í¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
                                    print(f"   - transcript: {transcript is not None}")
                                    print(f"   - model_turn: {model_turn is not None}")
                                    if model_turn:
                                        parts = getattr(model_turn, 'parts', [])
                                        print(f"   - parts ê°œìˆ˜: {len(parts)}")
                                print("\n") 
                                logger.flush_model_turn()

                    except Exception as e:
                        print(f"âš ï¸ ì‘ë‹µ ìˆ˜ì‹  ë£¨í”„ ì—ëŸ¬: {e}")
                        await asyncio.sleep(1)


            # [Task 5] RAG ê²€ìƒ‰ ë° ì»¨í…ìŠ¤íŠ¸ ì£¼ì…
            async def rag_loop():
                while shared_state["running"]:
                    try:
                        # íì—ì„œ í…ìŠ¤íŠ¸ êº¼ë‚´ê¸° (ì—†ìœ¼ë©´ ëŒ€ê¸°í•˜ì§€ ì•Šê³  ë„˜ì–´ê° -> timeout)
                        # wait for user input
                        try:
                            text = await asyncio.wait_for(rag_queue.get(), timeout=1.0)
                        except asyncio.TimeoutError:
                            continue

                        print(f"   ... ğŸ” ë§¤ë‰´ì–¼ ê²€ìƒ‰ ì¤‘: {text[:20]}...")
                        # Supabase ê²€ìƒ‰ (ë™ê¸° í•¨ìˆ˜ì´ë¯€ë¡œ ìŠ¤ë ˆë“œë¡œ ì‹¤í–‰)
                        results = await asyncio.to_thread(rag_engine.search, text)
                        
                        if results:
                            context_text = "\n".join(results)
                            msg = f"ì°¸ê³  ë§¤ë‰´ì–¼ ì •ë³´ (User Question: {text}):\n{context_text}"
                            print(f"   âœ… ê²€ìƒ‰ ì„±ê³µ ({len(results)}ê±´) -> ëª¨ë¸ì— ì£¼ì…")
                            
                            # ëª¨ë¸ì—ê²Œ í…ìŠ¤íŠ¸ë¡œ ì •ë³´ ì „ë‹¬ (end_of_turn=Falseë¡œ ì„¤ì •í•˜ì—¬ ë‹µë³€ ê°•ì œ íŠ¸ë¦¬ê±° ë°©ì§€)
                            # í•˜ì§€ë§Œ Live APIì—ì„œëŠ” í…ìŠ¤íŠ¸ë¥¼ ë³´ë‚´ë©´ ëª¨ë¸ì´ ì½ê³  ë°˜ì‘í•  ìˆ˜ ìˆìŒ
                            await session.send(input=msg, end_of_turn=False)
                        else:
                            print("   âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                            
                    except Exception as e:
                        print(f"RAG Loop Error: {e}")
                    
                    await asyncio.sleep(0.1)

            # [Task 6] Command Watcher
            async def command_watcher():
                # ì„¸ì…˜ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì¢…ë£Œ
                if not logger.session_ref:
                    print("âš ï¸ ì„¸ì…˜ì´ ìƒì„±ë˜ì§€ ì•Šì•„ command_watcherë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return

                current_session_id = logger.session_ref.id
                # Firestore ì°¸ì¡°
                db_client = firestore.client()
                session_doc_ref = db_client.collection('sessions').document(current_session_id)
                
                while shared_state["running"]:
                    try:
                        # polling ë°©ì‹ìœ¼ë¡œ 1ì´ˆë§ˆë‹¤ í™•ì¸ (Listenë³´ë‹¤ async ì¶©ëŒ ìœ„í—˜ì´ ì ìŒ)
                        doc = session_doc_ref.get()
                        command = None
                        if doc.exists:
                            command = doc.to_dict().get('command')
                        
                        if command == "summarize":
                            # ìš”ì•½ ë¡œì§ ì‹¤í–‰ (ë¹„ë™ê¸°)
                            await perform_summarization(client, current_session_id)
                        
                        await asyncio.sleep(1.0) # 1ì´ˆ ëŒ€ê¸°
                    except Exception as e:
                        print(f"Command Watcher Error: {e}")
                        await asyncio.sleep(1.0)                    

            # [Task 7] FastAPI Server (Spring Boot ì—°ë™)
            config = uvicorn.Config(app=app, host="0.0.0.0", port=8000, log_level="info")
            server = uvicorn.Server(config)

            tasks = [
                asyncio.create_task(display_loop()),
                asyncio.create_task(send_video()),
                asyncio.create_task(send_audio()),
                asyncio.create_task(receive_response()),
                asyncio.create_task(rag_loop()),
                asyncio.create_task(command_watcher()),
                asyncio.create_task(server.serve())
            ]
            
            done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)
            for task in pending: task.cancel()

    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()
    finally:
        if 'audio_player' in locals(): audio_player.close()
        if 'input_stream' in locals(): input_stream.stop_stream(); input_stream.close()
        if 'p' in locals(): p.terminate()
        if 'cap' in locals(): cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    asyncio.run(main())
